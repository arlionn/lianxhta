# 01.AI 在金融经济学中的应用综述(上)：从“更强的文本工具”到“金融信息基础设施”

本文基于 Mo and Ouyang ([2025](https://doi.org/10.1080/14765284.2025.2569006)) 的综述论文整理而成。读这篇综述最舒服的一点是：作者并不急着堆砌案例，而是先把“GenAI 在金融经济学中到底扮演什么角色”这件事讲清楚。你一旦接受了这个框架，再回头看近两年的热门论文，会发现它们并不杂乱，反而很容易归类、复用、迁移到自己的研究问题里。

这篇推文是上篇，目标是帮你建立一套“读文献坐标系”。它不追求把所有细节讲完，而是希望你读完之后能回答三个问题：

* 为什么 2022 年以后研究突然加速？
* LLM 在金融研究里最核心的价值到底是什么？
* “AI + 金融”的论文，常见的写法有哪些固定套路？

**温馨提示**：这篇综述涉及 255 篇论文，涵盖了金融经济学的多个子领域。为了便于大家快速定位到论文原文，查看 PDF 和 Google Scholar 链接，我已经把这篇综述的参考文献整理成了一个按主题分类的文献清单，方便读者查阅和后续研究使用。请参见连享会发布的另一篇推文：[255 篇论文：GenAI 在金融领域的各种应用](https://www.lianxh.cn/details/1711.html)。

---

## 1. 为什么 2022 年以后突然加速？这不是学术圈自嗨

很多人第一次看到“LLM + 金融”的论文，会产生一种不适感：它看起来像是在蹭热点，甚至像在卖课。但如果你把时间线拉长，会发现 2022 年之后的变化并不是偶然。

Mo and Ouyang ([2025](https://doi.org/10.1080/14765284.2025.2569006)) 手工整理了 2015-2025 年(截至 2025 年 8 月)金融经济学领域与 AI 相关的论文，并给出了一个非常直观的事实：2023-2024 年后论文数量明显加速，同时顶刊论文同步出现。这一波增长和技术节点高度重合，比如 Transformer、GPT 系列、ChatGPT、GPT-4 的发布，几乎就是“研究热度的时间轴”。

这张图你可以直接放到推文开头，读者一眼就知道：这是一波长期结构变化，不是短期噱头。

![B894-Fig01-20251119173103](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/B894-Fig01-20251119173103.png)

这件事还有一个外部证据：公众端的关注也在 2022 年末后快速上升。很多金融从业者并不读学术论文，但他们会用 ChatGPT 写摘要、读财报、做初步筛选。工具的普及反过来会抬高“市场信息处理能力”的平均水平，从而逼着学术研究往更深的机制层面走。

![B894-Fig02-20251119173508](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/B894-Fig02-20251119173508.png)

所以，如果你把 LLM 看成一次金融系统的信息基础设施升级，那么 2022 年之后的研究热度上升就很自然：金融本来就是信息密集型行业，AI 只要把信息处理成本打下来，几乎每个研究方向都会受到冲击。

---

## 2. 一个非常好用的总框架：工具、冲击、主体

Mo and Ouyang ([2025](https://doi.org/10.1080/14765284.2025.2569006)) 的核心贡献之一，是把 GenAI 在金融经济学中的作用总结为三种角色。这个划分特别“耐用”，因为它不仅能解释已有论文，也能帮助你做选题发散。

* **AI 作为分析工具(analytic tool)**
  你把它当成新型计量工具：预测、分类、抽取信息、构造变量、自动化文本处理流程。

* **AI 作为外生冲击(external shock)**
  你把它当成技术扩散冲击：ChatGPT 发布、企业采用 AI、行业扩散，都会改变市场的行为与制度环境。

* **AI 作为经济主体(economic agent)**
  你把它当成市场参与者：它不只是帮你读材料，而是直接给建议、做决策、执行交易，形成“人机混合市场”。

这三种视角有一个很关键的差异：
**工具视角解决“我能不能更好地测量”；冲击视角解决“环境变了会发生什么”；主体视角解决“参与者变了会发生什么”。**

很多读者喜欢问“LLM 能不能预测收益”。但在金融经济学里，更重要的通常不是预测能不能做到更准，而是：**谁因为 LLM 变得更快、更便宜、更稳定地处理信息？这种能力差异最终会落到资产价格、融资成本、治理结构、劳动市场的哪个环节？**

---

## 3. LLM 作为分析工具：它真正擅长的不是“算”，而是“读”

金融经济学传统上很强的一点，是它能把“信息不对称、注意力、叙事、预期”这些看不见摸不着的东西，变成可检验的实证变量。但过去我们受限于工具：文本处理很费劲，语义一致性很差，跨期跨行业比较难。

LLM 的价值首先在于：它把“读文本”变成了一种可规模化的计算任务。Mo and Ouyang ([2025](https://doi.org/10.1080/14765284.2025.2569006)) 将常见用法概括为四类：

* 预测
* 信息抽取
* 任务自动化
* 数据生成

下面逐个说清楚。

---

## 4. 输入端：金融研究的“新数据富矿”是什么？

先看一个很现实的问题：LLM 到底主要在处理什么类型的信息？
Mo and Ouyang ([2025](https://doi.org/10.1080/14765284.2025.2569006)) 统计了近期研究的输入数据来源，企业披露类信息占比最高，其次是新闻、社交媒体等。

![B894-Fig03-20251119173546](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/B894-Fig03-20251119173546.png)

这张图的含义可以概括为一句话：
金融研究正在从“结构化面板数据主导”，逐步走向“语义信息主导”。

结构化数据当然仍然重要，但真正能体现 LLM 优势的，往往是你以前很难处理、现在突然变得可处理的那部分信息，比如：

* 财报中的风险段落、MD&A 叙事
* 电话会议的 Q&A
* 分析师研报的逻辑链条
* 监管问询与回复
* 新闻中的解释框架与叙事变化

这些材料本来就存在，只是处理成本太高。LLM 把成本打下来了。

---

## 5. 预测：LLM 能不能预测收益率？先把问题问对

关于“LLM 预测回报”，市场上最爱讨论，但学术上最容易误解。因为“预测”这个词很容易让人以为：只要模型足够强，就能稳定赚钱。现实没这么简单。

更稳妥的理解是：LLM 改变了信息处理速度，从而改变价格对信息的反应过程。

一类典型研究是用 ChatGPT/GPT-4 对新闻标题做分类，并构造交易信号。例如 Lopez-Lira and Tang ([2023](https://doi.org/10.48550/arXiv.2304.07619)) 讨论了 LLM 在新闻驱动回报预测中的表现。你如果只看标题，会觉得它像量化交易论文；但往深一点看，它其实在回答一个老问题：新闻信息是否被市场及时吸收？LLM 是否降低了“理解新闻”这一步的摩擦？

另一条更重的路线，是用多语言新闻与全球市场大样本做系统评估。例如 Chen, Kelly, and Xiu ([2022](https://doi.org/10.2139/ssrn.4416687)) 讨论了大语言模型在多个市场、多个语言新闻中的预测表现。它的价值不在于告诉你“某个策略能赚多少钱”，而在于告诉你：哪些信息在全球范围内有共性、哪些信息高度本地化，模型能力与市场结构如何交互。

在经验上，如果你想把“LLM 预测”写成金融经济学论文，最好遵循三个原则：

* 不要只讲命中率，要讲机制：它到底抓住了什么信息摩擦？
* 不要只讲样本内拟合，要讲市场学习：策略是否会随扩散而衰减？
* 不要把预测当终点，而要把预测当“信息有效性检验”的手段

这样写，论文会更像金融经济学，而不是工程报告。

---

## 6. 信息抽取：从“词频”到“语义一致的经济变量”

过去金融文本分析常用字典法、词频、主题模型(LDA)。它们的优点是可复现、可解释，但缺点也很明显：语义粗糙，上下文容易失真。

LLM 更适合做的一件事是：把段落级文本转成结构化的经济变量。例如：

* 抽取管理层预期(偏乐观还是偏谨慎)
* 抽取风险披露的“具体性”(是否空泛、是否模板化)
* 抽取 Q&A 的沟通特征(是否答非所问、是否回避关键风险)
* 抽取政策文本的约束强度、关注重点、未来指引

这里的关键不是“模型说得像不像”，而是你要让它变成一个可比较、可检验的数值或分类标签。

很多好论文都遵循一个思路：
**LLM 负责测量，计量框架负责识别。**

你不必让 LLM 去“推断因果”，而是让它把不可观测的经济变量测得更准，然后把识别交给 DID、事件研究、IV 或结构模型。

---

## 7. 任务自动化：降低“读材料”的边际成本，改变信息摩擦

LLM 的另一个现实影响是：它让很多原本需要大量人工阅读的流程变得可自动化。例如：

* 自动摘要财报与公告要点
* 自动生成“问答式检索”，把披露材料变成可交互的数据库
* 自动标注风险主题、事件类型、监管条款
* 在投研流程中生成初稿、列出风险点、提示需要核验的细节

这类应用听起来偏“工具”，但它的经济学意义很强：
当信息处理成本下降，市场参与者的行为边界会改变。

过去我们默认散户难以读懂复杂文本，所以依赖中介(分析师、媒体)。但现在问题变成：散户是否因为工具而变得更接近“可读”？中介的作用会不会弱化？还是反而更重要，因为他们会用更高级的工具？

这就是金融经济学的典型问题：技术改变信息结构，信息结构改变市场行为。

---

## 8. 数据生成：最值得认真做的“变量工厂”

如果你想做更长期、更有含金量的研究方向，数据生成可能是 LLM 最重要的用途：它能把非结构化材料变成可回归的数据集。

你可以把它理解成“变量工厂”，常见产品包括：

* 用监管与政策文本生成制度强度、执行一致性指标
* 用企业业务描述生成竞争结构、行业网络、供应链语义距离
* 用专利与技术文本生成技术相似度、创新替代风险暴露
* 用问询函、诉讼材料生成合规风险、治理缺陷指标
* 用研报与电话会议生成市场分歧、叙事变化、预期修正

这类工作很容易写出“经济学味道”，因为它不是为了预测，而是为了测量一个理论上重要、但过去难以观测的变量。

---

## 9. 评估与约束：LLM 很强，但也很容易被误用

只要你认真做过文本研究，就会知道：工具越强，研究者自由度越大，越容易出现“看起来都对”的结果。因此，LLM 研究必须把约束写清楚。

* **时间一致性**：避免信息泄露，不要让模型用到后验信息
* **提示词敏感性**：prompt 是模型设定的一部分，必须报告与对比
* **输出稳定性**：同一任务多次运行的方差、不同模型版本的差异都应评估
* **可解释性边界**：不要把“语言流畅”当作“因果正确”

更稳健的策略仍然是：
让 LLM 做测量，把识别留给经典经济学设计。

---

## 10. 上篇小结：读文献时最该抓住的三句话

到这里，上篇可以收束成三条非常可复用的判断：

* 第一，GenAI 对金融经济学最稳定的贡献，是让语义信息可规模化、可结构化，从而降低信息处理成本。Mo and Ouyang ([2025](https://doi.org/10.1080/14765284.2025.2569006))
* 第二，很多“LLM 预测收益”的论文，深层讨论的是信息摩擦与市场效率，而不是永恒套利。
* 第三，真正值得长期投入的方向，是用 LLM 构造新变量、新网络、新暴露，让更多经济学机制可测量、可检验。

下篇我们转向读者最关心的部分：应用场景与选题发散。把“能做什么”讲透，才能形成头脑风暴。

如果你想先把文献地图铺开，可配合索引贴：
连小白, 2025, [255 篇论文:GenAI 在金融领域的各种应用](https://www.lianxh.cn/details/1711.html)

---

---

# 02.AI 在金融经济学中的应用综述(下)：应用场景、研究问题与选题发散(更适合头脑风暴)

本文继续基于 Mo and Ouyang ([2025](https://doi.org/10.1080/14765284.2025.2569006)) 的综述整理。上篇讲框架与方法，下篇专门讲“应用场景”。这也是多数读者最想看到的部分：你看完一堆论文标题之后，脑子里缺的往往不是知识点，而是一个清晰的问题库。

这篇推文的组织方式会更直接：我按领域列出一组高频应用场景，并尽量把它们翻译成“可写成论文的问题”。读者不需要把所有场景都记住，你只要在某一条上产生共鸣，就很可能延伸出一两个可做的研究设计。

---

## 1. 先强调一遍：应用不是堆案例，而是“机制翻译器”

很多 AI 应用的展示方式是：看，我能做摘要；看，我能预测；看，我能分类。
金融经济学更在意的是：这件事对应的经济机制是什么？

如果你接受 Mo and Ouyang ([2025](https://doi.org/10.1080/14765284.2025.2569006)) 的三重角色框架，那么任何应用都可以先问一句：

* 它是在帮我测量一个变量(工具)？
* 它是在改变市场环境(冲击)？
* 它是在替代或增强决策者(主体)？

下文的所有场景，都能落在这三个角度里。

---

## 2. 资产定价与交易：从“情绪信号”到“语义因子”

资产定价是 LLM 最容易切入的领域，因为它天然跟预测、交易相关。但真正能写成金融经济学论文的，往往不是“我预测得更准”，而是“我解释了信息如何进入价格”。

### 2.1 新闻情绪交易：从标题到叙事，从分类到机制

最常见的任务是：用 LLM 对新闻标题或新闻正文做分类，得到“好/坏/中性”或更细的情绪标签，再检验后续回报。

Lopez-Lira and Tang ([2023](https://doi.org/10.48550/arXiv.2304.07619)) 是这条路线的代表之一。它之所以引发广泛讨论，是因为它用一种非常直观的方式展示了：LLM 可以直接参与金融信息处理。

但如果你想让这类研究更像金融经济学，而不是“策略展示”，可以做三类升级：

* **从情绪到叙事**：同样是坏消息，到底是现金流坏、信用坏、政策坏，还是治理坏？
* **从标题到语境**：把新闻与公告、电话会议、研报连起来看，研究“解释链条”如何形成
* **从平均效应到异质性**：小盘股、信息不透明公司、投资者分歧大的股票是否更敏感？

这些升级都很自然，而且几乎不需要你训练新模型，只需要你把 LLM 当成语义测量工具。

### 2.2 多语言新闻与全球市场：LLM 的优势可能更在“可迁移”

如果你的研究场景是跨市场或国际金融，那么 LLM 的一个潜在优势是：它能处理多语言文本，减少跨国信息比较的障碍。

例如 Chen, Kelly, and Xiu ([2022](https://doi.org/10.2139/ssrn.4416687)) 讨论了大语言模型在多个市场、多个语言新闻中的预测表现。读这类研究时，你可以把重点放在“信息结构的跨国差异”上，而不是只盯着预测指标。

一个很容易延伸的问题是：

* 哪些信息在全球范围内是共性信号？
* 哪些信息高度依赖本地制度与语境？
* LLM 的迁移能力是否等价于“信息更可比”？还是会引入新的偏差？

### 2.3 语义因子：把文本风险暴露变成资产定价变量

资产定价越来越重视“因子解释”。LLM 很适合做的一件事，是把企业文本中隐含的风险主题提取出来，构造语义暴露，例如：

* 政策不确定性暴露
* 信用风险叙事暴露
* AI 相关风险暴露
* 气候风险叙事暴露

然后你可以做三步：

* 先检验这些暴露是否预测横截面回报或波动
* 再检验它们是否与传统因子(价值、动量、盈利能力等)独立
* 最后讨论它们是风险补偿还是注意力/行为偏差

这种写法非常“资产定价”，也更容易站得住。

### 2.4 趋势、学习与“解释性”：别把 AI 只当预测器

在更宽的机器学习资产定价路线里，Jiang, Kelly, and Xiu ([2023](https://doi.org/10.1111/jofi.13268)) 讨论了如何用更灵活的学习方法理解价格趋势。它的启发是：很多经典现象(比如动量、趋势)可能不是某个固定规则，而是市场在高维信息下的行为结果。

把这条线索接到 LLM 上，一个很自然的问题是：

* 当文本语义信息变得更充分时，趋势效应会变弱还是变强？
* 语义信号与价格趋势是否互补？
* LLM 的扩散是否会让某些异常收益逐步消失？

这就把“模型能力”转成“市场机制变化”，更适合金融经济学写法。

---

## 3. 公司金融：披露、融资、治理、契约与组织结构

公司金融领域的应用看起来更分散，但其实可以用一句话串起来：

**LLM 降低了读懂企业信息的成本，这会改变融资约束、治理结构与组织决策。**

### 3.1 财报与 MD&A：披露质量的语义度量

过去我们度量披露质量，常用可读性指标、字典情绪、篇幅、复杂度。LLM 的优势在于，它可以更接近“内容本身”：

* 风险披露是否具体，还是模板化敷衍
* 同一公司跨期披露是否语义一致，是否前后矛盾
* 披露是否回避关键问题，还是主动解释

把这些语义度量做成指标后，你可以自然进入公司金融的经典问题：

* 披露质量是否影响融资成本与流动性？
* 披露是否预测未来诉讼、监管问询与违约？
* 市场是否能区分“真披露”与“话术披露”？

### 3.2 电话会议(Q&A)：管理层预期与沟通策略

电话会议是 LLM 特别适合的场景，因为它的文本更“口语化”，包含大量微妙信息：

* 管理层对未来需求的预期是否转弱
* 回答是否回避、是否答非所问
* 分析师提问是否更尖锐、更集中

在论文写法上，这类研究非常容易落地：

* 让 LLM 提取管理层预期指标
* 用事件研究检验公告日反应
* 再用面板回归检验对投资、融资、裁员的预测能力

最重要的是，这类问题有清晰经济含义：它在研究预期形成与信息披露机制。

### 3.3 分析师研报：观点分歧、注意力配置与信息中介

分析师研报的价值不只是“给评级”，而是中介信息。LLM 可以帮助你做更细的研报结构化：

* 提取核心论据是什么(增长、风险、估值、政策)
* 提取观点分歧来自哪里(对需求、成本、政策的判断差异)
* 提取关注点变化(从增长转向风险，从盈利转向现金流)

然后你可以写出很多经典问题的新版本：

* 研报分歧是否预测波动与成交量？
* 研报的“论据结构”是否比评级更能解释市场反应？
* 当投资者也用 LLM 读研报时，中介作用是否会弱化？

### 3.4 融资约束与信息不对称：谁从“读得懂”中获益？

LLM 普及并不意味着信息平等。相反，它可能带来新的不平等：不同投资者采用工具的能力不同。

这类研究可以往两个方向写：

* **信息差缩小**：散户因为工具变得更接近“可读”，信息不对称下降
* **信息差扩大**：机构先用起来，且更会用，优势反而扩大

你可以用很金融经济学的方式表达它：
LLM 改变了信息获取成本函数，这会影响市场微观结构与价格发现过程。

---

## 4. 金融中介与风控：合同条款、合规文本与监管互动

这一块是很多研究者忽视的金矿，因为它看起来不那么“性感”，但非常容易做成高质量论文。

### 4.1 契约与条款：把 covenant 变成可计算对象

很多金融合同都充满长文本条款，过去很难规模化抽取。LLM 特别适合做：

* covenant 类型识别(财务约束、行为约束)
* 触发条件抽取
* 条款强度与严苛程度分类
* 违约后果条款识别

这类研究的落点非常清晰：

* 条款强度如何影响融资成本、违约概率、企业投资行为？
* 银行在不同周期是否更倾向于使用更严苛条款？
* 条款是否在行业间存在系统性差异？

### 4.2 监管问询与合规：风险暴露的制度化测量

如果你研究的是上市公司监管环境，那么问询函与回复是极好的文本材料。LLM 可以帮助你构造：

* 问询主题(财务真实性、关联交易、收入确认、重大风险)
* 回复质量(是否具体、是否回避、是否“模板化安抚”)
* 事件后果(是否引发处罚、是否影响融资与股价)

这类研究很容易与治理质量、信息披露、市场反应结合。

---

## 5. 家庭金融：信用评分、Robo-advisor 与行为干预

家庭金融的 AI 应用更贴近服务端，读起来也更直观。它的核心问题仍然是：信息、激励与不平等。

### 5.1 信用评分：替代数据的双刃剑

AI 信贷常被描述为“提升普惠金融”。逻辑是：用更多软信息减少信息不对称，让传统信用记录不足的人获得融资机会。

但它同时可能带来算法歧视与黑箱问题。你可以把研究问题写得很清楚：

* 替代数据是否真正提高了准入，而不是只提高利润？
* 模型是否对不同群体产生系统性差异？
* 监管要求的可解释性在 LLM 时代如何实现？

这类研究往往不需要训练大模型，你只需要让 LLM 抽取软信息特征，再结合传统实证框架即可。

### 5.2 Robo-advisor：它到底改善了什么？

Robo-advisor 的表面目标是降低投资门槛，但更有意思的问题是：

* 它是通过降低搜索成本改善决策？
* 还是通过“更强说服力”改变风险偏好？
* 当 AI 的解释非常流畅时，用户是否更容易过度信任？

这类问题把家庭金融的经典主题(有限理性、说服与误导、注意力约束)重新带回来，非常适合做机制讨论。

### 5.3 对话式财务助理：低成本干预的可能性

对话式 AI 还可能用于预算管理、负债规划、风险提示。这种干预方式成本低、覆盖广，很适合做：

* 采用行为的决定因素分析(谁更愿意使用？是否存在数字鸿沟？)
* 真实行为变化评估(储蓄、负债、投资风险暴露是否变化？)

设计上可做 RCT 或准实验，也容易与政策评估结合。

---

## 6. 劳动市场：AI 冲击不是“有没有工作”，而是“任务怎么变”

金融行业的一个现实变化是：很多白领岗位的任务结构正在重组。

* 初级分析师：整理、摘要、写初稿更容易被自动化
* 高级分析师：判断、责任、客户沟通变得更关键
* 合规风控：文本筛查效率显著提高，但责任边界更复杂

把“工作”拆成任务(task)后，你会更容易写出可解释结论：AI 是替代部分任务、增强部分任务，从而改变工资结构、晋升路径与技能溢价。

---

## 7. 系统性风险与治理：最大风险不是“模型不准”，而是同步化

讨论应用不能只谈“好处”，还要谈“系统性后果”。在金融语境中，我更倾向于把风险分为三层：

* **微观误导风险**：幻觉、偏见导致个体决策错误
* **市场同步风险**：大量参与者用相似模型与数据源，导致同向交易与踩踏
* **制度治理风险**：责任归属、审计追溯、数据与模型产权边界

其中“市场同步风险”正在变得越来越现实：
当大家用相似的 LLM 读同一条新闻、同一份财报，市场反应可能更一致、更快。这会提高效率，也可能让系统更脆弱。

这类问题一旦写出来，往往就不再是“工具应用”，而是金融经济学的核心议题：市场微观结构如何决定波动与脆弱性。

---

## 8. 一组更直接的选题清单(用于头脑风暴)

为了让读者更快把应用场景转成研究问题，最后给一组更“论文格式”的问题清单。每一条都可以自然写出假设、变量、识别与机制：

* **信息不对称**：LLM 降低阅读成本后，散户与机构的信息差是缩小还是扩大？
* **注意力与叙事**：同一事件在不同媒体叙事下，市场反应是否不同？能否构造“叙事强度指数”？
* **披露质量**：语义一致性是否预测未来诉讼、问询、违约？
* **政策沟通**：监管与央行文本的风险关注点变化，是否领先于市场波动？
* **公司网络**：用业务描述生成语义网络，能否解释并购匹配与冲击传导？
* **基金行为**：从基金报告抽取宏观信念，是否预测调仓与风格漂移？
* **家庭金融**：AI 顾问是否改善资产配置，还是诱发过度信任与过度交易？
* **劳动市场**：金融岗位任务替代是否改变工资结构与晋升路径？
* **系统性风险**：模型同质化是否导致波动放大与踩踏风险？

这些选题有一个共同点：你不需要证明 LLM 比人聪明，你只需要证明它改变了信息结构，进而改变经济行为。

---

## 9. 下篇小结：应用的尽头是“信息结构与激励结构”的变化

Mo and Ouyang ([2025](https://doi.org/10.1080/14765284.2025.2569006)) 的综述给出的最大启发并不是“列出了多少应用”，而是把应用背后的机制串起来：

* LLM 降低信息处理成本
* 信息结构发生变化
* 激励结构与市场行为随之调整
* 最终影响价格、融资、治理、劳动与风险

如果你希望进一步按主题查论文，仍建议配合索引贴使用：
连小白, 2025, [255 篇论文:GenAI 在金融领域的各种应用](https://www.lianxh.cn/details/1711.html)

---

## 10. 文内引用格式补充(用于正文写作)

在正文中引用时，尽量采用如下形式，并将年份链接到 DOI：

`Authors ([Year](https://doi.org/{DOI}))`

示例：

* Abadie, Diamond, and Hainmueller ([2010](https://doi.org/10.1198/jasa.2009.ap08746))
* Arkhangelsky et al. ([2021](https://doi.org/10.1257/aer.20190159))
